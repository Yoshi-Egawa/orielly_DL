{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 誤差伝播法\n",
    "- 重みパラメータの勾配の計算を効率良く行う方法\n",
    "\n",
    "## 連鎖律\n",
    "- 端的に合成関数の微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乗算\n",
    "class MulLayer:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        return x * y\n",
    "    \n",
    "    def backward(self, d_out):\n",
    "        d_x = d_out * self.y\n",
    "        d_y = d_out * self.x\n",
    "\n",
    "        return d_x, d_y\n",
    "\n",
    "# 加算\n",
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return x + y\n",
    "    \n",
    "    def backward(self, d_out):\n",
    "        d_x = d_out\n",
    "        d_y = d_out\n",
    "\n",
    "        return d_x, d_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU\n",
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def backward(self, d_out):\n",
    "        d_out[self.mask] = 0\n",
    "        d_x = d_out\n",
    "        return d_x\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# sigmoid\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, d_out):\n",
    "        d_x = d_out * (1.0 - self.out) * self.out\n",
    "        return d_x\n",
    "\\\n",
    "\n",
    "import sys\n",
    "sys.path.append('./deep-learning-from-scratch')\n",
    "from common.functions import *\n",
    "\n",
    "# Affine\n",
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.d_W = None\n",
    "        self.d_b = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        out = np.dot(x, self.W) + self.b\n",
    "        return out\n",
    "\n",
    "    def backward(self, d_out):\n",
    "        d_x = np.dot(d_out, self.W.T)\n",
    "        self.d_W = np.dot(self.x.T, d_out)\n",
    "        self.d_b = np.sum(d_out, axis=0)\n",
    "        return d_x\n",
    "\n",
    "# softmax with loss\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self, d_out=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        d_x = (self.y - self.t) / batch_size\n",
    "        return d_x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 誤差伝播法を使った２層ニューラルネットワーク\n",
    "import sys\n",
    "sys.path.append('./deep-learning-from-scratch')\n",
    "\n",
    "import numpy as np\n",
    "from common.gradient import numerical_gradient\n",
    "from collections import OrderedDict\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        self.params = {\n",
    "            'W1': weight_init_std * np.random.randn(input_size, hidden_size),\n",
    "            'b1': np.zeros(hidden_size),\n",
    "            'W2': weight_init_std * np.random.randn(hidden_size, output_size),\n",
    "            'b2': np.zeros(output_size),\n",
    "        }\n",
    "\n",
    "        # レイヤの作成\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers[\"Affine1\"] = Affine(self.params['W1'], self.params['b1'])\n",
    "        self.layers[\"ReLU1\"] = ReLU()\n",
    "        self.layers[\"Affine2\"] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(x, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "\n",
    "        accuracy = np.sum(y == t / float(x.shape[0]))\n",
    "        return accuracy\n",
    "    \n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        grads = {\n",
    "            \"W1\": numerical_gradient(loss_W, self.params['W1']),\n",
    "            \"b1\": numerical_gradient(loss_W, self.params['b1']),\n",
    "            \"W2\": numerical_gradient(loss_W, self.params['W2']),\n",
    "            \"b2\": numerical_gradient(loss_W, self.params['b2']),\n",
    "        }\n",
    "        return grads\n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        d_out = 1\n",
    "        d_out = self.lastLayer.backward(d_out)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        \n",
    "        for layer in layers:\n",
    "            d_out = layer.backward(d_out)\n",
    "\n",
    "        grads = {\n",
    "            \"W1\": self.layers[\"Affine1\"].d_W,\n",
    "            \"b1\": self.layers[\"Affine1\"].d_b,\n",
    "            \"W2\": self.layers[\"Affine2\"].d_W,\n",
    "            \"b2\": self.layers[\"Affine2\"].d_b,\n",
    "        }\n",
    "\n",
    "        return grads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/orielly_DL/learn_backpropagation.ipynb Cell 6\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f796f7368696869726f2e65676177612f6d792d6170702f6f7269656c6c795f444c222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f796f7368696869726f2e65676177612f6d792d6170702f6f7269656c6c795f444c2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f796f7368696869726f2e65676177612f6d792d6170702f6f7269656c6c795f444c2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f796f7368696869726f2e65676177612f6d792d6170702f6f7269656c6c795f444c2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/orielly_DL/learn_backpropagation.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m./deep-learning-from-scratch/ch05\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f796f7368696869726f2e65676177612f6d792d6170702f6f7269656c6c795f444c222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f796f7368696869726f2e65676177612f6d792d6170702f6f7269656c6c795f444c2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f796f7368696869726f2e65676177612f6d792d6170702f6f7269656c6c795f444c2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f796f7368696869726f2e65676177612f6d792d6170702f6f7269656c6c795f444c2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/orielly_DL/learn_backpropagation.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f796f7368696869726f2e65676177612f6d792d6170702f6f7269656c6c795f444c222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f796f7368696869726f2e65676177612f6d792d6170702f6f7269656c6c795f444c2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f796f7368696869726f2e65676177612f6d792d6170702f6f7269656c6c795f444c2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f796f7368696869726f2e65676177612f6d792d6170702f6f7269656c6c795f444c2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/orielly_DL/learn_backpropagation.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdataset\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmnist\u001b[39;00m \u001b[39mimport\u001b[39;00m load_mnist\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f796f7368696869726f2e65676177612f6d792d6170702f6f7269656c6c795f444c222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f796f7368696869726f2e65676177612f6d792d6170702f6f7269656c6c795f444c2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f796f7368696869726f2e65676177612f6d792d6170702f6f7269656c6c795f444c2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f796f7368696869726f2e65676177612f6d792d6170702f6f7269656c6c795f444c2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/orielly_DL/learn_backpropagation.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtwo_layer_net\u001b[39;00m \u001b[39mimport\u001b[39;00m TwoLayerNet\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f796f7368696869726f2e65676177612f6d792d6170702f6f7269656c6c795f444c222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f796f7368696869726f2e65676177612f6d792d6170702f6f7269656c6c795f444c2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f796f7368696869726f2e65676177612f6d792d6170702f6f7269656c6c795f444c2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f796f7368696869726f2e65676177612f6d792d6170702f6f7269656c6c795f444c2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/orielly_DL/learn_backpropagation.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m (x_train , t_train), (x_test, t_test) \u001b[39m=\u001b[39m load_mnist(normalize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, one_hot_label\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dataset'"
     ]
    }
   ],
   "source": [
    "# ミニバッチの実装\n",
    "import sys\n",
    "sys.path.append('./deep-learning-from-scratch')\n",
    "sys.path.append('./deep-learning-from-scratch/ch05')\n",
    "\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "\n",
    "(x_train , t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_loss_list = []\n",
    "\n",
    "# ハイパーパラメータ\n",
    "iters_num = 10_000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "\n",
    "    for key in network.params.keys():\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
